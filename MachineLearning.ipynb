{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MachineLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GK1dFsH7bFN",
        "colab_type": "text"
      },
      "source": [
        "#Lab 01. TensorFlow 기초"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMTJgb6273PB",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow 불러오기 및 버전 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSw6VV16lfTD",
        "colab_type": "code",
        "outputId": "86c9aa1f-b075-45ba-d920-9c5dae5b49f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aynoTxB7_CP",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow 기본 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v6g1fG978Mw",
        "colab_type": "code",
        "outputId": "36e7c15c-54f5-4ea0-f64a-62e46e350b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hello = tf.constant(\"Hello, TensorFlow!\")\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "print(sess.run(hello))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello, TensorFlow!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2jCAMzC8pLX",
        "colab_type": "text"
      },
      "source": [
        "Session이라는 것을 만들고, sess.run을 통해서 이 노드를 출력한다.\n",
        "b라는 것은 bytes string이라는 것이다. 신경쓰지 말 것."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krjKptB38IDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "node1 = tf.constant(3.0, tf.float32)\n",
        "node2 = tf.constant(4.0)\n",
        "node3 = tf.add(node1, node2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6AjcPgm8Kgv",
        "colab_type": "code",
        "outputId": "d919c4ea-d317-4294-f67b-0f4bb2c55e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"node1:\", node1, \"node2:\", node2)\n",
        "print(\"node3: \", node3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "node1: Tensor(\"Const_1:0\", shape=(), dtype=float32) node2: Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
            "node3:  Tensor(\"Add:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUcig6Ty9jlo",
        "colab_type": "text"
      },
      "source": [
        "단순 출력을 할 경우, node가 어떤 텐서라는 것을 알려준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T42S2DxG8RiR",
        "colab_type": "code",
        "outputId": "58b68d85-5bc8-47ae-a929-f53b5de6a22d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "print(\"sess.run(node1, node2): \", sess.run([node1, node2]))\n",
        "print(\"sess.run(node3): \", sess.run(node3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sess.run(node1, node2):  [3.0, 4.0]\n",
            "sess.run(node3):  7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxhNwnt79mKv",
        "colab_type": "text"
      },
      "source": [
        "이렇게 sess.run을 통해 실행시켜주어야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAHmgCUI9rkf",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow 순서를 보면, graph를 build하고, sess.run을 통해 graph를 실행시키고, 그 결과가 나오는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PR1d09k8Zvg",
        "colab_type": "code",
        "outputId": "2d869169-0a81-4d92-d338-3850acafbf95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a = tf.placeholder(tf.float32)\n",
        "b = tf.placeholder(tf.float32)\n",
        "adder_node = a + b\n",
        "\n",
        "print(sess.run(adder_node, feed_dict ={a: 3, b: 4.5}))\n",
        "print(sess.run(adder_node, feed_dict={a: [1,3], b: [2,4]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.5\n",
            "[3. 7.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzVHtxIM93Z5",
        "colab_type": "text"
      },
      "source": [
        "미리 graph를 만들고, 그 값을 나중에 주고 싶다면?\n",
        "> placeholder라는 노드를 만들어서 나중에 feed_dict를 통해 값을 넘겨준다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuTyFd6J_Kpw",
        "colab_type": "text"
      },
      "source": [
        "#Lab 02. Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-RdQ375zYgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# X and Y data\n",
        "x_train = [1, 2, 3]\n",
        "y_train = [1, 2, 3]\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = x_train * W + b\n",
        "\n",
        "#cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
        "\n",
        "# Minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session\n",
        "sess = tf.Session()\n",
        "# Initializes global variables in the graph\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Fit the line\n",
        "for step in range(2001):\n",
        "  sess.run(train)\n",
        "  if step % 20 == 0:\n",
        "    print(step, sess.run(cost), sess.run(W), sess.run(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_9EoC_0AWC0",
        "colab_type": "text"
      },
      "source": [
        "먼저, cost가 무엇인지를 그 값을 설명한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pvk86xWAMdM",
        "colab_type": "text"
      },
      "source": [
        "GradientDescent를 활용하여 minimize를 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1cJ8t06AeMM",
        "colab_type": "text"
      },
      "source": [
        "여기서는 w와 b는 variables이고, 이를 사용하기 위해서는 global_variables_initializer()가 실행되어야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NzWjCsuAuP0",
        "colab_type": "text"
      },
      "source": [
        "근데, train만 실행시켜도 그래프를 따라서 w와 b값에 역시 변화가 생긴다. 이때 학습이 일어나고, 그 과정에서 20번에 한번씩 그 결과를 보는 것."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQBL74a4zpmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "X = tf.placeholder(tf.float32, shape=[None])\n",
        "Y = tf.placeholder(tf.float32, shape=[None])\n",
        "\n",
        "hypothesis = X * W + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  W_val, b_val, _ = sess.run([W, b, train],\n",
        "              feed_dict={X: [1., 2., 3., 4., 5.], Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
        "  if step % 20 == 0:\n",
        "    print(step, W_val, b_val)\n",
        "  if step % 2000 == 0:\n",
        "    cost_val = sess.run([cost], feed_dict={X:[1., 2., 3., 4., 5.], Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
        "    print(cost_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTOgrmI6B1Ir",
        "colab_type": "text"
      },
      "source": [
        "Placeholder를 이용하여 값의 변화를 용이하게 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etG-oilUEP-B",
        "colab_type": "text"
      },
      "source": [
        "즉, 먼저 그래프 모델을 만든 후에 그 값을 넘겨줄 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLqNMuiX5doh",
        "colab_type": "code",
        "outputId": "73ef1728-973b-4ce5-f259-89dbee3a9a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
        "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
        "print(sess.run(hypothesis, feed_dict={X: [1.5,3.5]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.100773]\n",
            "[3.5993826]\n",
            "[2.5988266 4.5999384]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQlvEXfJEVX_",
        "colab_type": "text"
      },
      "source": [
        "학습한 모델이 잘 하는가? Hypothesis에 X값을 줘서 맞는 값이 나오는지 확인할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQoundd3EqcR",
        "colab_type": "text"
      },
      "source": [
        "여기서 보면 X값에 +1.1이 되어야 하므로 꽤 잘 나오는 것을 볼 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr1pxL4IEwcG",
        "colab_type": "text"
      },
      "source": [
        "#Lab 03. Cost 최소화 TensorFlow로 구현해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GNureUFFYxu",
        "colab_type": "text"
      },
      "source": [
        "기존에는 optimize.minimize()를 사용하였지만, 이제 이걸 TensorFlow로 구현해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLkyyr2B-kuY",
        "colab_type": "code",
        "outputId": "12d9025c-fc66-4def-85ad-8ba26850db09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "X = [1, 2, 3]\n",
        "Y = [1, 2, 3]\n",
        "\n",
        "W = tf.placeholder(tf.float32)\n",
        "\n",
        "#Simple Model (exclude + b)\n",
        "hypothesis = X * W\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "W_val = []\n",
        "cost_val = []\n",
        "for i in range(-30, 50):\n",
        "  feed_W = i * 0.1\n",
        "  curr_cost, curr_W = sess.run([cost, W], feed_dict={W:feed_W})\n",
        "  W_val.append(curr_W)\n",
        "  cost_val.append(curr_cost)\n",
        "  \n",
        "plt.plot(W_val, cost_val)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7x2zAT0FxRs",
        "colab_type": "text"
      },
      "source": [
        "w_val과 cost_val을 이용하여 w와 cost의 값을 저장할 리스트를 만든다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB4TYZ88F4V4",
        "colab_type": "text"
      },
      "source": [
        "-3에서 5까지 0.1정도 간격으로 움직일 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG4Q0_-tGQAm",
        "colab_type": "text"
      },
      "source": [
        "여기서 계속 w를 변화시키면서 그걸 토대로 다시 변화시키고, plt.plot()함수를 이용하여 x축이 w, y축이 cost 인 그래프를 그린다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVdp5P_iBbHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.1\n",
        "gradient = tf.reduce_mean((W * X - Y) * X)\n",
        "descent = W - learning_rate * gradient\n",
        "update = W.assign(descent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4yctd-1Gukv",
        "colab_type": "text"
      },
      "source": [
        "cost 함수를 미분 = 기울기를 구한다. 이때, 기울기가 음수이면 w는 줄어들어야하고, 기울기가 양수이면 w는 증가해야한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knzdFX8JHMGB",
        "colab_type": "text"
      },
      "source": [
        "gradient는 기울기로, 수식을 그대로 써주고 mean()함수를 통해 평균 낸다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrh6X6lFHbBS",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow는 바로 대입하는 것이 아니라 W.assign과 같은 식으로 assign() 함수를 이용하여 대입할 수 있다. 이를 update로 가져오는 것이고, 여기서 이 update를 실행시키는 것."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzS6xGLnB3Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "x_data = [1, 2, 3]\n",
        "y_data = [1, 2, 3]\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "hypothesis = X * W\n",
        "\n",
        "cost = tf.reduce_sum(tf.square(hypothesis - Y))\n",
        "\n",
        "learning_rate = 0.1\n",
        "gradient = tf.reduce_mean((W * X - Y) * X)\n",
        "descent = W - learning_rate * gradient\n",
        "update = W.assign(descent)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for step in range(21):\n",
        "  sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
        "  print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT83aEPTIJ8s",
        "colab_type": "text"
      },
      "source": [
        "실행할수록 cost는 작아지고, w는 1에 가까운 수가 된다. (그래프와 일치))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozDvMarOIe8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "X = [1, 2, 3]\n",
        "Y = [1, 2, 3]\n",
        "\n",
        "W = tf.Variable(5.0)\n",
        "\n",
        "hypothesis = X * W\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(21):\n",
        "  print(step, sess.run(W))\n",
        "  sess.run(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0gpQmGmI-ar",
        "colab_type": "text"
      },
      "source": [
        "위의 코드에서 W의 값을 5로 바꿔도, -3으로 바꿔도 결국 W는 1로 수렴한다. (실행시)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BFevo4XJxsE",
        "colab_type": "text"
      },
      "source": [
        "#Lab 04-1. 다변수 linear regression 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llnvr7chMH_-",
        "colab_type": "text"
      },
      "source": [
        "여기서는 x1, x2, x3 세개의 변수를 사용한다. x가 많을수록 더 정밀한 값이 나온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohm-czUEMY2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1_data = [73., 93., 89., 96., 73.]\n",
        "x2_data = [80., 88., 91., 98., 66.]\n",
        "x3_data = [75., 93., 90., 100., 70.]\n",
        "y_data = [152., 185., 180., 196., 142.]\n",
        "\n",
        "x1 = tf.placeholder(tf.float32)\n",
        "x2 = tf.placeholder(tf.float32)\n",
        "x3 = tf.placeholder(tf.float32)\n",
        "\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
        "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
        "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for step in range(2001):\n",
        "  cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
        "                        feed_dict={x1:x1_data, x2:x2_data, x3:x3_data, Y:y_data})\n",
        "  if step % 10 == 0:\n",
        "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__VAvDAkONUK",
        "colab_type": "text"
      },
      "source": [
        "결국 다변수이기 때문에 hypothesis 식이 변한 것 외에는 별다른 차이가 없음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHcS4TmlOodH",
        "colab_type": "text"
      },
      "source": [
        "위의 단점은, 변수의 수에 따라서 코드가 너무 더러워 진다는 것이다. 여기서 Matrix를 이용한다. 아래에서 구현해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHloiLhBOt9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = [[73., 80., 75.], [93., 88., 93.],\n",
        "          [89., 91., 90.], [96., 86., 100.], [73., 66., 70.]]\n",
        "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for step in range(2001):\n",
        "  cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
        "                        feed_dict={x1:x1_data, x2:x2_data, x3:x3_data, Y:y_data})\n",
        "  if step % 10 == 0:\n",
        "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_DQophlPmg-",
        "colab_type": "text"
      },
      "source": [
        "눈여겨 보아야 할 것: shape[]. 여기서, x의 변수 개수가 3개 이므로 None, **3**으로 설정해준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG-u2LFFP9o8",
        "colab_type": "text"
      },
      "source": [
        "여기서 None의 의미는 3개씩 세트로 몇개가 들어올지 모른다는 것을 의미한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odsHfzyPQhGu",
        "colab_type": "text"
      },
      "source": [
        "tf.matmul 함수를 이용하여 Matrix간 곱셈을 해준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wKA77TEQpOB",
        "colab_type": "text"
      },
      "source": [
        "#Lab 04-2. 파일에서 Data 읽어오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYWY2_OyRngy",
        "colab_type": "text"
      },
      "source": [
        "이제 많은 x 데이터, y 데이터를 파일에서 읽어와보자!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLilrnitQxou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.set_random_seed(777)\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "xy = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]\n",
        "\n",
        "print(x_data.shape, x_data, len(x_data))\n",
        "print(y_data.shape, y_data)\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for step in range(2001):\n",
        "  cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
        "                        feed_dict={X :x_data, Y:y_data})\n",
        "  if step % 10 == 0:\n",
        "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
        "    \n",
        "#print(\"Your score will be \", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))\n",
        "#print(\"Other scores will be \", sess.run(hypothesis, feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0owirCv5W0F3",
        "colab_type": "text"
      },
      "source": [
        "Colab에서 파일을 받아오기 위해 from google.colab import files를 사용. 파일명은 똑같아야 함에 유의."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4djsuBOFXBDq",
        "colab_type": "text"
      },
      "source": [
        "나머지는 같은 방식. 중간에 슬라이싱을 이용하여 데이터에서 원하는 부분만 골라온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn3khYbhWdX_",
        "colab_type": "code",
        "outputId": "103e238b-d289-4e2d-a3a9-65795d15e8a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Your score will be \", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))\n",
        "print(\"Other scores will be \", sess.run(hypothesis, feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your score will be  [[198.51953]]\n",
            "Other scores will be  [[166.61644]\n",
            " [171.42914]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfUx3n7hXHc3",
        "colab_type": "text"
      },
      "source": [
        "sess.run을 hypothesis에 대해 함으로써 나/친구들의 점수를 예측할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeP3txzCXm2d",
        "colab_type": "text"
      },
      "source": [
        "그렇다면 파일 하나로 데이터를 담기에 너무 큰 경우에는 어떡하는가? (메모리에 한번에 올리기 힘든 경우)\n",
        "> Queue Runner라는 시스템을 이용하여 해결."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmO-vVNIYKcB",
        "colab_type": "text"
      },
      "source": [
        "Queue Runner는 여러개의 파일을 Queue에 쌓고, Reader를 통해 읽은 다음 데이터 양식에 맞게 Decoder 작업을 거치고 (콤마 등을 읽어들이고), 이를 다시 Queue에 쌓는다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f59R2QbkZDHK",
        "colab_type": "text"
      },
      "source": [
        "즉, queue에서 필요한 batch만큼 꺼내서 사용하는 방식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5utqgA0XNjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename_queue = tf.train.string_input_producer(\n",
        "  ['data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
        "\n",
        "reader = tf.TextLineReader()\n",
        "key, value = reader.read(filename_queue)\n",
        "\n",
        "record_defaults = [[0.], [0.], [0.], [0.]]\n",
        "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
        "\n",
        "train_x_batch, train_y_batch = \\\n",
        "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "coord = tf.train.Coordinator()\n",
        "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "\n",
        "\n",
        "for step in range(2001):\n",
        "  x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
        "  cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
        "                        feed_dict={X: x_batch, Y: y_batch})\n",
        "  if step % 10 == 0:\n",
        "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
        "    \n",
        "coord.request_stop()\n",
        "coord.join(threads)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFVMmspAb3zL",
        "colab_type": "text"
      },
      "source": [
        "버전의 차이로 오류 발생하는 것으로 보임. 추후에는 삭제될 예정..?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTAoo4Gp996L",
        "colab_type": "text"
      },
      "source": [
        "#Lab 05. Logistic (regression) classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DRYTRLvAAxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6,2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "W = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
        "\n",
        "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)\n",
        "\n",
        "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y)\n",
        "                       * tf.log(1 - hypothesis))\n",
        "\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  for step in range(10001):\n",
        "    cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
        "    if step % 200 == 0:\n",
        "      print(step, cost_val)\n",
        "      \n",
        "  h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
        "                    feed_dict = {X: x_data, Y: y_data})\n",
        "  print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIDHmQGLEBap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "W = tf.Variable(tf.random_normal([8,1]), name = 'weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
        "\n",
        "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)\n",
        "\n",
        "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y)\n",
        "                       * tf.log(1 - hypothesis))\n",
        "\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  for step in range(10001):\n",
        "    cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
        "    if step % 200 == 0:\n",
        "      print(step, cost_val)\n",
        "      \n",
        "  h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
        "                    feed_dict = {X: x_data, Y: y_data})\n",
        "  print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-1o9mjqFAtL",
        "colab_type": "text"
      },
      "source": [
        "#Lab 06-1. Softmax Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X_6NxZwFMVb",
        "colab_type": "code",
        "outputId": "a9695122-d468-4b7a-9195-7324b5d4ef21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_data = [[1, 2, 1, 1],\n",
        "          [2, 1, 3, 2],\n",
        "          [3, 1, 3, 4],\n",
        "          [4, 1, 5, 5],\n",
        "          [1, 7, 5, 5],\n",
        "          [1, 2, 5, 6],\n",
        "          [1, 6, 6, 6],\n",
        "          [1, 7, 7, 7]]\n",
        "y_data = [[0, 0, 1],\n",
        "          [0, 0, 1],\n",
        "          [0, 0, 1],\n",
        "          [0, 1, 0],\n",
        "          [0, 1, 0],\n",
        "          [0, 1, 0],\n",
        "          [1, 0, 0],\n",
        "          [1, 0, 0]]\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, 4])\n",
        "Y = tf.placeholder(\"float\", [None, 3])\n",
        "nb_classes = 3\n",
        "\n",
        "W = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
        "\n",
        "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
        "\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(2001):\n",
        "            sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
        "\n",
        "            if step % 200 == 0:\n",
        "                print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
        "    \n",
        "    a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9]]})\n",
        "    print(a, sess.run(tf.argmax(a, 1)))\n",
        "    \n",
        "    all = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9], [1, 3, 4, 3], [1, 1, 0, 1]]})\n",
        "    print(all, sess.run(tf.argmax(all, 1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3.990404\n",
            "200 0.45643815\n",
            "400 0.36585695\n",
            "600 0.28904897\n",
            "800 0.23350662\n",
            "1000 0.21082\n",
            "1200 0.19221675\n",
            "1400 0.17662254\n",
            "1600 0.16334234\n",
            "1800 0.15189072\n",
            "2000 0.14191325\n",
            "[[1.1493531e-03 9.9884063e-01 9.9683111e-06]] [1]\n",
            "[[1.1493509e-03 9.9884063e-01 9.9683111e-06]\n",
            " [9.2805517e-01 6.0245000e-02 1.1699834e-02]\n",
            " [6.6459380e-09 2.7481050e-04 9.9972516e-01]] [1 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RlF5AweHIUtP"
      },
      "source": [
        "#Lab 06-2. Fancy Softmax Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLzIaWnGJOl5",
        "colab_type": "code",
        "outputId": "cf6b9449-47a6-4c59-cb0a-c7b301610d3b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "xy = np.loadtxt('data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]\n",
        "\n",
        "print(x_data.shape, y_data.shape)\n",
        "\n",
        "nb_classes = 7\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 16])\n",
        "Y = tf.placeholder(tf.int32, [None, 1])\n",
        "\n",
        "Y_one_hot = tf.one_hot(Y, nb_classes)\n",
        "print(\"one_hot:\", Y_one_hot)\n",
        "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])\n",
        "print(\"reshape one_hot:\", Y_one_hot)\n",
        "\n",
        "\n",
        "W = tf.Variable(tf.random_normal([16, nb_classes]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
        "\n",
        "logits = tf.matmul(X, W) + b\n",
        "hypothesis = tf.nn.softmax(logits)\n",
        "\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
        "                                                                 labels=tf.stop_gradient([Y_one_hot])))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "prediction = tf.argmax(hypothesis, 1)\n",
        "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(2001):\n",
        "        _, cost_val, acc_val = sess.run([optimizer, cost, accuracy], feed_dict={X: x_data, Y: y_data})\n",
        "                                        \n",
        "        if step % 100 == 0:\n",
        "            print(\"Step: {:5}\\tCost: {:.3f}\\tAcc: {:.2%}\".format(step, cost_val, acc_val))\n",
        "\n",
        "   \n",
        "    pred = sess.run(prediction, feed_dict={X: x_data})\n",
        "    \n",
        "    for p, y in zip(pred, y_data.flatten()):\n",
        "        print(\"[{}] Prediction: {} True Y: {}\".format(p == int(y), p, int(y)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43db78cf-e1bd-42bd-ac37-652b86955471\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-43db78cf-e1bd-42bd-ac37-652b86955471\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data-04-zoo.csv to data-04-zoo.csv\n",
            "(101, 16) (101, 1)\n",
            "one_hot: Tensor(\"one_hot:0\", shape=(?, 1, 7), dtype=float32)\n",
            "reshape one_hot: Tensor(\"Reshape:0\", shape=(?, 7), dtype=float32)\n",
            "Step:     0\tCost: 3.287\tAcc: 11.88%\n",
            "Step:   100\tCost: 0.533\tAcc: 82.18%\n",
            "Step:   200\tCost: 0.334\tAcc: 93.07%\n",
            "Step:   300\tCost: 0.252\tAcc: 94.06%\n",
            "Step:   400\tCost: 0.205\tAcc: 95.05%\n",
            "Step:   500\tCost: 0.174\tAcc: 97.03%\n",
            "Step:   600\tCost: 0.151\tAcc: 99.01%\n",
            "Step:   700\tCost: 0.134\tAcc: 99.01%\n",
            "Step:   800\tCost: 0.120\tAcc: 99.01%\n",
            "Step:   900\tCost: 0.108\tAcc: 99.01%\n",
            "Step:  1000\tCost: 0.099\tAcc: 99.01%\n",
            "Step:  1100\tCost: 0.091\tAcc: 99.01%\n",
            "Step:  1200\tCost: 0.084\tAcc: 99.01%\n",
            "Step:  1300\tCost: 0.078\tAcc: 100.00%\n",
            "Step:  1400\tCost: 0.073\tAcc: 100.00%\n",
            "Step:  1500\tCost: 0.068\tAcc: 100.00%\n",
            "Step:  1600\tCost: 0.064\tAcc: 100.00%\n",
            "Step:  1700\tCost: 0.060\tAcc: 100.00%\n",
            "Step:  1800\tCost: 0.057\tAcc: 100.00%\n",
            "Step:  1900\tCost: 0.054\tAcc: 100.00%\n",
            "Step:  2000\tCost: 0.052\tAcc: 100.00%\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 5 True Y: 5\n",
            "[True] Prediction: 4 True Y: 4\n",
            "[True] Prediction: 4 True Y: 4\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 5 True Y: 5\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 5 True Y: 5\n",
            "[True] Prediction: 5 True Y: 5\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 5 True Y: 5\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 5 True Y: 5\n",
            "[True] Prediction: 4 True Y: 4\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 2 True Y: 2\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 2 True Y: 2\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 2 True Y: 2\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 5 True Y: 5\n",
            "[True] Prediction: 4 True Y: 4\n",
            "[True] Prediction: 2 True Y: 2\n",
            "[True] Prediction: 2 True Y: 2\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 5 True Y: 5\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 1 True Y: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TvSwzRysLYC",
        "colab_type": "text"
      },
      "source": [
        "hi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-chdCvCsL9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}